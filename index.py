# index.py (VERSÃƒO OTIMIZADA)
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re

# Base de conhecimento expandida
conhecimento = {
    # TERMOS BÃSICOS
    "fit": "O mÃ©todo fit() Ã© usado para treinar modelos de machine learning. Ele recebe os dados de treino X (features) e y (target) e ajusta os parÃ¢metros do modelo para aprender os padrÃµes dos dados.",
    
    "predict": "O predict() faz previsÃµes usando um modelo jÃ¡ treinado. Ele recebe novos dados de entrada e retorna as previsÃµes baseadas no que o modelo aprendeu durante o treinamento.",
    
    "naive bayes": "Naive Bayes Ã© um algoritmo de classificaÃ§Ã£o rÃ¡pido e eficiente, especialmente bom para trabalhar com dados de texto como emails e documentos. Ã‰ baseado no teorema de Bayes e assume que as features sÃ£o independentes.",
    
    "random forest": "Random Forest Ã© um algoritmo ensemble que combina mÃºltiplas Ã¡rvores de decisÃ£o. Cada Ã¡rvore Ã© treinada com uma amostra diferente dos dados, e a previsÃ£o final Ã© a mÃ©dia ou votaÃ§Ã£o de todas as Ã¡rvores. Ã‰ muito preciso mas pode ser mais lento.",
    
    "cross validation": "Cross validation Ã© uma tÃ©cnica para avaliar a performance de modelos. Divide os dados em vÃ¡rias partes (folds), treina o modelo em algumas partes e testa nas outras. Recomendo usar 10 folds para a maioria dos projetos.",
    
    "feature engineering": "Feature engineering Ã© o processo de criar, selecionar e transformar variÃ¡veis para melhorar o desempenho do modelo. Representa cerca de 80% do trabalho de um engenheiro de machine learning.",
    
    # PERGUNTAS PRÃTICAS - COMO FAZER
    "como calcular regressÃ£o linear": "Para calcular regressÃ£o linear: primeiro importe LinearRegression do sklearn, prepare seus dados separando features e target, divida em treino e teste com train_test_split, crie o modelo, use fit() para treinar com os dados de treino, depois use predict() para fazer previsÃµes nos dados de teste e finalmente avalie com mÃ©tricas como RÂ² score.",
    
    "como calcular acurÃ¡cia": "Para calcular acurÃ¡cia, use a funÃ§Ã£o accuracy_score do sklearn.metrics, passando os valores verdadeiros e as previsÃµes do modelo. A acurÃ¡cia mostra a porcentagem de previsÃµes corretas. VocÃª tambÃ©m pode usar model.score() diretamente no modelo treinado.",
    
    "como escolher algoritmo": "Para escolher o algoritmo: se for classificaÃ§Ã£o (categorias), use Random Forest ou Naive Bayes; se for regressÃ£o (nÃºmeros), use Linear Regression ou Random Forest Regressor; para dados de texto, Naive Bayes Ã© excelente; para mÃ¡xima precisÃ£o com tempo suficiente, Random Forest Ã© Ã³timo.",
    
    "como lidar com dados faltantes": "Para dados faltantes: vocÃª pode remover as linhas com valores faltantes usando dropna(), ou preencher os valores: use a mÃ©dia para nÃºmeros, moda para categorias, ou algoritmos de imputaÃ§Ã£o como SimpleImputer do sklearn.",
    
    "quantos dados preciso para treinar": "O mÃ­nimo recomendado Ã© 1000 amostras para problemas simples, mas idealmente 10.000+ para modelos robustos. Para deep learning, sÃ£o necessÃ¡rios 50.000+ amostras. A qualidade dos dados Ã© mais importante que a quantidade.",
    
    "como saber se meu modelo Ã© bom": "Um modelo Ã© bom quando: tem alta acurÃ¡cia nos dados de teste (nÃ£o sÃ³ treino), generaliza bem para novos dados, as mÃ©tricas de avaliaÃ§Ã£o sÃ£o consistentes, e nÃ£o mostra overfitting (quando performa bem no treino mas mal no teste).",
    
    "o que Ã© overfitting": "OVERFITTING: Ocorre quando um modelo de ML se ajusta excessivamente aos dados de treino, memorizando ruÃ­dos em vez de padrÃµes gerais. SINAIS: Alta acurÃ¡cia no treino (>95%), baixa no teste (<70%). SOLUÃ‡ÃƒO: Mais dados, regularizaÃ§Ã£o, cross-validation.",
    
    "como evitar overfitting": "Para evitar overfitting: use mais dados de treino, faÃ§a cross-validation, aplique regularizaÃ§Ã£o (L1, L2), use tÃ©cnicas de ensemble como Random Forest, simplifique o modelo, ou use dropout em redes neurais.",
    
    "qual diferenÃ§a entre ai machine learning e deep learning": "AI Ã© o campo geral, machine learning Ã© subcampo onde mÃ¡quinas aprendem com dados, e deep learning Ã© um tipo especÃ­fico de machine learning que usa redes neurais com muitas camadas. Deep learning precisa de mais dados mas pode resolver problemas mais complexos.",
    
    "como comeÃ§ar na Ã¡rea de ia": "Para comeÃ§ar em IA: aprenda Python, estude matemÃ¡tica bÃ¡sica (estatÃ­stica, Ã¡lgebra), pratica com projetos simples, aprenda bibliotecas como sklearn e tensorflow, participe de competiÃ§Ãµes no Kaggle, e construa um portfolio com projetos reais.",
    
    "quanto tempo leva para aprender machine learning": "Leva 3-6 meses para aprender o bÃ¡sico e construir projetos simples, 1 ano para se tornar proficiente, e 2+ anos para se tornar especialista. O importante Ã© praticar consistentemente e construir projetos reais.",
    
    "quais bibliotecas devo aprender": "As bibliotecas essenciais sÃ£o: pandas para manipulaÃ§Ã£o de dados, numpy para computaÃ§Ã£o numÃ©rica, matplotlib e seaborn para visualizaÃ§Ã£o, scikit-learn para machine learning tradicional, e tensorflow ou pytorch para deep learning.",
    
    "como conseguir emprego na Ã¡rea": "Para conseguir emprego: construa um portfolio com projetos reais no GitHub, participe de competiÃ§Ãµes no Kaggle, faÃ§a networking, aprenda a explicar modelos para nÃ£o-tÃ©cnicos, e mostre experiÃªncia prÃ¡tica resolvendo problemas reais.",

    # ğŸ”§ CONHECIMENTOS SOBRE OVERFITTING
    "overfitting": "OVERFITTING: Ocorre quando um modelo de ML se ajusta excessivamente aos dados de treino, memorizando ruÃ­dos em vez de padrÃµes gerais. SINAIS: Alta acurÃ¡cia no treino (>95%), baixa no teste (<70%). SOLUÃ‡ÃƒO: Mais dados, regularizaÃ§Ã£o, cross-validation.",
    
    "underfitting": "Underfitting Ã© o oposto do overfitting. Ocorre quando o modelo Ã© muito simples e nÃ£o consegue capturar os padrÃµes dos dados. Resulta em performance ruim tanto nos dados de treino quanto teste. SoluÃ§Ã£o: usar modelo mais complexo ou mais features.",
    
    "overfitting e underfitting": "Overfitting Ã© quando o modelo Ã© muito complexo e decora os dados. Underfitting Ã© quando o modelo Ã© muito simples e nÃ£o aprende os padrÃµes. O ideal Ã© encontrar o equilÃ­brio onde o modelo generaliza bem para dados novos.",
    
    "regularizaÃ§Ã£o": "RegularizaÃ§Ã£o Ã© uma tÃ©cnica para prevenir overfitting adicionando uma penalidade aos parÃ¢metros do modelo. L1 (Lasso) tende a zerar alguns coeficientes, L2 (Ridge) reduz todos os coeficientes. Ambas ajudam o modelo a generalizar melhor.",
    
    "bias e variÃ¢ncia": "Bias Ã© o erro por suposiÃ§Ãµes muito simplistas (causa underfitting). VariÃ¢ncia Ã© o erro por sensibilidade a pequenas flutuaÃ§Ãµes nos dados (causa overfitting). O tradeoff bias-variÃ¢ncia busca equilibrar esses dois erros.",
    
    "validaÃ§Ã£o cruzada": "Cross-validation Ã© uma tÃ©cnica para avaliar modelos dividindo os dados em k partes (folds). Treina em k-1 partes e testa na parte restante, repetindo k vezes. Isso dÃ¡ uma estimativa mais confiÃ¡vel da performance e ajuda a detectar overfitting.",
    
    "como detectar overfitting": "Para detectar overfitting: compare a performance nos dados de treino vs teste. Se a acurÃ¡cia no treino for muito maior que no teste, hÃ¡ overfitting. Cross-validation e curva de aprendizado tambÃ©m ajudam na detecÃ§Ã£o.",
    
    "early stopping": "Early stopping Ã© uma tÃ©cnica usada em treinamento iterativo (como redes neurais) onde paramos o treinamento quando a performance no validation set para de melhorar. Isso previne overfitting automaticamente.",
    
    "dropout": "Dropout Ã© uma tÃ©cnica de regularizaÃ§Ã£o para redes neurais onde aleatoriamente 'desligamos' alguns neurÃ´nios durante o treinamento. Isso previne que a rede dependa muito de neurÃ´nios especÃ­ficos e melhora a generalizaÃ§Ã£o.",
    
    # ğŸ¯ SINÃ”NIMOS E VARIAÃ‡Ã•ES
    "floresta aleatÃ³ria": "Random Forest Ã© um algoritmo ensemble que combina mÃºltiplas Ã¡rvores de decisÃ£o. Cada Ã¡rvore Ã© treinada com uma amostra diferente dos dados, e a previsÃ£o final Ã© a mÃ©dia ou votaÃ§Ã£o de todas as Ã¡rvores.",
    
    "engenharia de features": "Feature engineering Ã© o processo de criar, selecionar e transformar variÃ¡veis para melhorar o desempenho do modelo. Representa cerca de 80% do trabalho de um engenheiro de machine learning.",
    
    "sobreajuste": "Sobreajuste (overfitting) ocorre quando um modelo de ML se ajusta excessivamente aos dados de treino, memorizando ruÃ­dos em vez de padrÃµes gerais.",
    
    # ğŸ§  CONHECIMENTOS AVANÃ‡ADOS
    "gradient descent": "Gradient Descent Ã© um algoritmo de otimizaÃ§Ã£o usado para encontrar os parÃ¢metros que minimizam a funÃ§Ã£o de custo. Ele calcula o gradiente (derivada) e ajusta os parÃ¢metros na direÃ§Ã£o que reduz o erro.",
    
    "backpropagation": "Backpropagation Ã© o algoritmo usado para treinar redes neurais. Ele calcula o gradiente da funÃ§Ã£o de custo em relaÃ§Ã£o a todos os pesos na rede, propagando o erro das camadas de saÃ­da para as camadas de entrada.",
    
    "activation function": "FunÃ§Ãµes de ativaÃ§Ã£o introduzem nÃ£o-linearidade nas redes neurais. As principais sÃ£o: ReLU (mais comum), Sigmoid (para probabilidades), Tanh e Softmax (para multi-classificaÃ§Ã£o).",
    
    "learning rate": "Learning rate Ã© um hiperparÃ¢metro que controla o tamanho dos passos durante o treinamento com Gradient Descent. Muito alto: pode divergir. Muito baixo: treinamento lento.",
}

# FunÃ§Ã£o OTIMIZADA com mÃºltiplas camadas
def responder_pergunta(pergunta):
    pergunta = pergunta.lower().strip()
    
    # ğŸš€ PRIMEIRO: COMBINAÃ‡Ã•ES EXATAS (antes da busca exata)
    combinacoes_exatas = {
        # Overfitting
        "explique overfitting": conhecimento["overfitting"],
        "o que Ã© overfitting": conhecimento["overfitting"],
        "como evitar overfitting": conhecimento["como evitar overfitting"],
        "fale sobre overfitting": conhecimento["overfitting"],
        "defina overfitting": conhecimento["overfitting"],
        "o que significa overfitting": conhecimento["overfitting"],
        "conceito de overfitting": conhecimento["overfitting"],
        "overfitting em machine learning": conhecimento["overfitting"],
        
        # RegressÃ£o Linear
        "me explique regressÃ£o linear": conhecimento["como calcular regressÃ£o linear"],
        "o que Ã© regressÃ£o linear": conhecimento["como calcular regressÃ£o linear"],
        "como implementar regressÃ£o linear": conhecimento["como calcular regressÃ£o linear"],
        "regressÃ£o linear em python": conhecimento["como calcular regressÃ£o linear"],
        "passos para regressÃ£o linear": conhecimento["como calcular regressÃ£o linear"],
        "modelo de regressÃ£o linear": conhecimento["como calcular regressÃ£o linear"],
        "aplicaÃ§Ãµes de regressÃ£o linear": conhecimento["como calcular regressÃ£o linear"],
        
        # Feature Engineering
        "engenharia de features": conhecimento["feature engineering"],
        "como criar features": conhecimento["feature engineering"],
        "tÃ©cnicas de feature engineering": conhecimento["feature engineering"],
        "importÃ¢ncia da engenharia de features": conhecimento["feature engineering"],
        "feature engineering para ml": conhecimento["feature engineering"],
        
        # Random Forest
        "floresta aleatÃ³ria": conhecimento["random forest"],
        "explique floresta aleatÃ³ria": conhecimento["random forest"],
    }
    
    if pergunta in combinacoes_exatas:
        return combinacoes_exatas[pergunta]
    
    # ğŸš€ DEPOIS: Busca EXATA tradicional
    for palavra_chave, resposta in conhecimento.items():
        if palavra_chave in pergunta:
            return resposta
    
    # ğŸš€ FINALMENTE: Busca por SIMILARIDADE
    perguntas_lista = list(conhecimento.keys())
    respostas_lista = list(conhecimento.values())
    
    # Adiciona a pergunta do usuÃ¡rio Ã  lista
    todas_perguntas = perguntas_lista + [pergunta]
    
    # Calcula similaridade
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(todas_perguntas)
    
    # Similaridade entre a pergunta e todas as outras
    similaridades = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
    
    # Encontra a mais similar
    indice_mais_similar = similaridades.argmax()
    similaridade_maxima = similaridades.max()
    
    # Se for suficientemente similar, retorna a resposta
    if similaridade_maxima > 0.5:
        return respostas_lista[indice_mais_similar]
    else:
        return "ğŸ¤” NÃ£o tenho certeza sobre isso. VocÃª pode reformular a pergunta ou me ensinar sobre esse tÃ³pico?"

# Interface
def main():
    st.set_page_config(
        page_title="Meu CÃ©rebro IA", 
        page_icon="ğŸ§ ",
        layout="centered"
    )
    
    st.title("ğŸ§  Meu Assistente Pessoal de IA")
    st.markdown("---")
    
    st.write("**Pergunte anything sobre Machine Learning!**")
    
    # Input da pergunta
    pergunta = st.text_input(
        "Digite sua pergunta:",
        placeholder="Ex: Como calcular regressÃ£o linear? O que Ã© overfitting?"
    )
    
    # BotÃ£o de enviar
    if st.button("Perguntar") or pergunta:
        if pergunta.strip():
            with st.spinner("ğŸ§  Pensando..."):
                resposta = responder_pergunta(pergunta)
                
                st.success("**Resposta:**")
                st.info(resposta)
        else:
            st.warning("âš ï¸ Digite uma pergunta!")

if __name__ == "__main__":
    main()